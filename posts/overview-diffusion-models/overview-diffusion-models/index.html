<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width">
		

		<title>An overview of the latest progress in Generative Diffusion Models</title>

		
		<link rel="stylesheet" href="https://halixness.github.io/css/colors-gray.min.79dd1eeea55d2f828756abc012d14281edab73aa717888b50e711c8645c268e5.css">
		<link rel="icon" href="https://halixness.github.io/favicon.ico"> 

		<head>
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">


    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>


    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>


    
    <link rel="stylesheet" type="text/css" href="https://halixness.github.io/hugo-cite.css" />
</head>
	</head>
	<body>
			
			<section id="contained-engraving"></section>

			
			<header id="header">
				<h1><a href="https://halixness.github.io">Diego Calanzone</a></h1>
				<p class="description">
					Deep learning student, software engineer. Made in üáÆüáπ.
					<br>
					(refresh to see many üêª)
				</p>

			</header>

			
			<div id="page">

				
				<div id="sidebar">
					<nav>
	
		<hr class="menu-line">
		<ul class="nav">
			
				<li>
					
					<a href="https://halixness.github.io/about"><span>About</span></a>
					
				</li>
			
				<li>
					
					<a href="https://halixness.github.io/"><span>Blog</span></a>
					
				</li>
			
				<li>
					
					<a href="https://halixness.github.io/projects"><span>Projects</span></a>
					
				</li>
			
		</ul>
		<hr class="menu-line">
	
</nav>

				</div>

				
				<div id="content">
					
	<article class="post">

		
			<h1 class="single-title"><a href="https://halixness.github.io/posts/overview-diffusion-models/overview-diffusion-models/">An overview of the latest progress in Generative Diffusion Models</a> </h1>
		

		<div class="single-content post-content"><h2 id="langevin-dynamics-score-based-generative-models">Langevin Dynamics, Score-Based Generative Models</h2>
<p>Our generation has a philosopher.
He is not an artist, or a professional writer.
He is a programmer. 




)</span>
</p>
<ul>
<li>Based on the <strong>Metropolis-Hastings algorithm:</strong>
<ul>
<li><em>idea</em>: use a markov chain (process of sequential random variables) whose equilibrium distribution approximates the desired one</li>
<li>algorithm: define a proposed approximating distribution g(x). \(x^* = x_t + \mathcal{N}(0, \sigma^2 I * f\left(u\right))\)
. Compute \(A=\min \left(1, \frac{\pi(y) Q\left(x_t \mid y\right)}{\pi\left(x_t\right) Q\left(y \mid x_t\right)}\right)\),  with probability \(A\)  we accept \(x_{t-1} = x^<em>\), otherwise keep \(x_{t-1} = x_t$. What does this imply? We want  $g(x^</em>)\) to be higher ‚Üí towards the data. Repeat the process.</li>
</ul>
</li>
<li><strong>Langevin Dynamics:</strong> generate samples of p(x) without knowing it.
<ul>
<li>algorithm (<a href="https://www.stats.ox.ac.uk/~teh/research/compstats/WelTeh2011a.pdf">Welling, Teh, 2011</a>): initialize x0. x_t+1 = x_t + stepsize * gradients score fn + gaussian noise. The score function is log of likelihood (p(x|params), aka circa the density) ‚Üí the score function is approx. by a neural network s_theta(x). To cover lacking regions of data: perturbate the set with various noise scales sequentially, estimate score for each distribution w/ certain scale ‚Üí Annealed Langevin dynamics (<a href="https://arxiv.org/abs/2006.09011">Song, Ermon, 2020</a>).</li>
<li>target: from data, the NN for score learns a data distribution and how to maximize its likelihood. It will learn to add/remove noise from images and with proper denoising/re-noising, genetive behaviour is observed.</li>
</ul>
</li>
</ul>
<h2 id="conditioning-in-score-based-generative-models">Conditioning in Score-Based Generative Models</h2>
<ul>
<li>
<p><strong>Classifier Guidance: c</strong>onditional sampling (<a href="https://arxiv.org/abs/2105.05233">Dhariwal, Nichol, 2021</a>) of variables depends on a small change in the score function:</p>
<ul>
<li>idea:  $p_{\theta}\left(x_{t}\right) p_{\phi}\left(y \mid x_{t}\right)$ the gradient of log of these is the sum of gradients of log likelihoods for each model. A new network predicts to remove noise in a new joint distribution:</li>
</ul>
<p>$$
\begin{aligned}\nabla_{x_{t}} \log \left(p_{\theta}\left(x_{t}\right) p_{\phi}\left(y \mid x_{t}\right)\right) &amp;=\nabla_{x_{t}} \log p_{\theta}\left(x_{t}\right)+\nabla_{x_{t}} \log p_{\phi}\left(y \mid x_{t}\right) \&amp;=-\frac{1}{\sqrt{1-\bar{\alpha}<em>{t}}} \epsilon</em>{\theta}\left(x_{t}\right)+\nabla_{x_{t}} \log p_{\phi}\left(y \mid x_{t}\right)\end{aligned}
$$</p>
<p>$$
\hat{\epsilon}\left(x_{t}\right):=\epsilon_{\theta}\left(x_{t}\right)-\sqrt{1-\bar{\alpha}<em>{t}} \nabla</em>{x_{t}} \log p_{\phi}\left(y \mid x_{t}\right)
$$</p>
<ul>
<li>algorithm: during the denoising process, the  vector $x_{i=t&hellip;0}$ is fed to a classifier (ie: CLIP, with a text prompt ‚Üí compute a loss ie: spherical loss) ‚Üí gradients are computed, thus a new sample $x_{i-1}$ will be taken from a gaussian with predicted mean, shifted by the classifier‚Äôs gradient. A sketch of CLIP-guided diffusion:</li>
</ul>
<p><img src="Generative%20diffusion%20models%209d1f7fae218549048c050ea653e86aa2/IMG_C0784AE33AC2-1.jpeg" alt="IMG_C0784AE33AC2-1.jpeg"></p>
</li>
<li>
<p><strong>Cross attention:</strong> the paper from <a href="https://arxiv.org/abs/2112.10752">(Rombach et al., 2021)</a> introduces a form of conditioning expanded to text, images encoded from a backbone $\tau_{\phi}$ .</p>
<ul>
<li>idea: the denoising network  $\epsilon_{\theta}$ has a U-Net structure and cross attention is added for each step $z_t \rightarrow z_{t-1}$ with the conditioning embedding from $\tau_{\phi}$</li>
</ul>
<p><img src="Generative%20diffusion%20models%209d1f7fae218549048c050ea653e86aa2/Schermata_2022-08-31_alle_12.27.17.png" alt="Schermata 2022-08-31 alle 12.27.17.png"></p>
<ul>
<li>training: the denoising network $\epsilon_{\theta}$ needs to be trained in order to correctly process $z_t$ and the vector $\tau_{\phi}(u)$, where $u$ is the conditioning signal. Thus several trained versions of the model are released for impainting, text to img etc.</li>
</ul>
</li>
</ul>
</div>

		
			<h1>
				Date: <p class="meta"></p> <span class="postdate">28. December 2021</span></p> 
			</h1>
		

		
			<h1>
				Tags:  <p class="tag">diffusion </p>   <p class="tag">generative </p>  
			</h1> 
		

	</article>

	<style>
		.meta {
			display: inline-block;
		}
	</style>

				</div>

				
				<footer id="footer">
					<p class="copyright">
						
							¬© Diego Calanzone 2021
						
					</p>
				</footer>
			</div>
		


<script async src="https://www.googletagmanager.com/gtag/js?id=UA-216110268-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-216110268-1');
</script>






		
		<script type="text/javascript">

			
			engravings = 6;
			index = Math.floor(Math.random() * (engravings));
			document.getElementById("contained-engraving").style.backgroundImage = "url('/images/engravings/" + index + ".svg')";

		</script>
	</body>
</html>
